{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d88754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install seaborn pandas matplotlib numpy    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a46bc5",
   "metadata": {},
   "source": [
    "every successive data of each device id were in an interval of approx 60 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70699995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import pandas as pd \n",
    "from datetime import date , time \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from traceback import print_exc\n",
    "import datetime\n",
    "file_names = [\"m1.csv\" , \"m2.csv\" , \"m3.csv\" , \"m4.csv\"]\n",
    "save_path = \"combined_mahanagar_data.csv\" \n",
    "rcp = \"rush_clasified.csv\" #rush_classified_path\n",
    "dpd = \"data_per_day.csv\" #data_per_day\n",
    "save_path_2 = \"data_tracking.csv\"\n",
    "columns = [\"distance\" , \"totalDistance\" , \"deviceId\",\"fixTime\",\"latitude\",\"longitude\",\"speed\"]\n",
    "total_bus , total_dates = [],[]\n",
    "dates_given = ['2020-02-23', '2019-08-22', '2020-02-24', '2020-02-25', '2020-02-26', '2020-02-27', '2020-02-28', '2020-02-06', '2020-01-27', '2020-02-07', '2020-02-08', '2020-02-09', '2020-02-10', '2020-02-11', '2020-02-14', '2020-02-15', '2020-02-16', '2020-02-17', '2020-02-18', '2020-02-19', '2020-02-20']\n",
    "dict_dates = {\n",
    "        key:0 for key in dates_given \n",
    "        \n",
    "    }\n",
    "dict_dates_2 = {\n",
    "    key:[0,0,0] for key in dates_given\n",
    "}\n",
    "buses = [130, 2, 131, 132, 133, 134, 135, 136, 200, 137, 73, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 169]\n",
    "total_buses = {}\n",
    "total_dates = []\n",
    "folder_img = \"distance_vs_time\"\n",
    "\n",
    "def make_int(x):\n",
    "    x=str(x)\n",
    "    \n",
    "    y=list(x)\n",
    "    \n",
    "    if \"-\" in y:\n",
    "        y = x \n",
    "        year = int(\"\".join(x[0:4]))\n",
    "        month = int(\"\".join(x[5:7]))\n",
    "        day = int(\"\".join(x[8:10]))\n",
    "        return year , month , day\n",
    "    else:\n",
    "        year = int(\"\".join(x[0:2]))\n",
    "        month = int(\"\".join(x[3:5]))\n",
    "        day = int(\"\".join(x[6:8]))\n",
    "        return year , month , day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "total_lines = 0\n",
    "def try_float_convert(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (ValueError, TypeError):\n",
    "        \n",
    "        return value\n",
    "with open(save_path ,\"w\",newline=\"\") as file:\n",
    "    writer_file = csv.DictWriter(file , fieldnames=columns)\n",
    "    writer_file.writeheader()\n",
    "    for name in file_names:\n",
    "        with open(name ,\"r\") as csv_file: \n",
    "            reader = csv.DictReader(csv_file)\n",
    "            \n",
    "            \n",
    "            \n",
    "            for line in reader:\n",
    "                lines_to_write = [\n",
    "                    try_float_convert(line[cols])  \n",
    "                    for cols in columns \n",
    "                    #if line[cols] not in columns and line[\"alarm\"]!=\"powerCut\"\n",
    "                    if line[cols] not in columns\n",
    "                    ]\n",
    "                try:\n",
    "                    dict_temp = {\n",
    "                    columns[0]:lines_to_write[0],\n",
    "                    columns[1]:lines_to_write[1],\n",
    "                    columns[2]:int(lines_to_write[2]),\n",
    "                    columns[3]:lines_to_write[3],\n",
    "                    columns[4]:lines_to_write[4],\n",
    "                    columns[5]:lines_to_write[5],\n",
    "                    columns[6]:lines_to_write[6],\n",
    "                }\n",
    "                    writer_file.writerow(dict_temp)\n",
    "                    dict_temp={}\n",
    "                    total_lines+=1 \n",
    "                except:\n",
    "                    pass \n",
    "    file.close()\n",
    "print(f\" a total of {total_lines} were created in {save_path}\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff7971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def date_parser(dates):\n",
    "    listed = []\n",
    "    i=1\n",
    "    print(dates[:10])\n",
    "    for date in dates:\n",
    "        \n",
    "        i+=1        \n",
    "        stinged = list(date)\n",
    "        \n",
    "        year = int(float(\"\".join(stinged[0:4])))\n",
    "        month = int(float(\"\".join(stinged[5:7])))\n",
    "        day=int(float(\"\".join(stinged[8:10])))\n",
    "        time1 = time(int(float(\"\".join(stinged[11:13]))),int(float(\"\".join(stinged[14:16]))) , int(float(\"\".join(stinged[17:19]))))\n",
    "        \n",
    "        d1=datetime.date(year,month , day)\n",
    "        \n",
    "        listed.append(str(datetime.datetime.combine( d1, time1))) \n",
    "    return listed\n",
    "df = pd.read_csv(save_path,header=0)\n",
    "\n",
    "df[\"fixTime\"] = date_parser(df[\"fixTime\"])\n",
    "df.to_csv(save_path , index = False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497734ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            \n",
    "with open(save_path , \"r\") as file:\n",
    "    \n",
    "    lines = csv.DictReader(file)\n",
    "    temp_recorder = [[0,0,0] for _ in range(0 , 41)]\n",
    "\n",
    "    \n",
    "\n",
    "    for line in lines:\n",
    "        #print(line)\n",
    "        device_id = int(line[\"deviceId\"])\n",
    "        indexed = buses.index(device_id)\n",
    "        \n",
    "        time1 = line[\"fixTime\"]\n",
    "        time1 = time1.split() \n",
    "        yr , mon ,day = make_int(time1[0]) \n",
    "        hr,min,sec =  make_int(time1[1]) \n",
    "        # if time1[0] not in dates_given:\n",
    "        #     dates_given.append(time1[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #morning_peak 0 , free_hour 1 , evening_peak 2\n",
    "        hour_time = 0 if 8<=hr<=11 else (1 if 11<hr<16 else (2 if 15<=hr<=19 else 1))\n",
    "        temp_recorder[indexed][hour_time]+=1\n",
    "        dict_dates[time1[0]]+=1\n",
    "        some_data = dict_dates_2[time1[0]]\n",
    "        some_data[hour_time]+=1 \n",
    "        dict_dates_2[time1[0]] = some_data\n",
    "    file.close()\n",
    "with open(rcp , \"w\") as rcp_writer:\n",
    "    writer = csv.DictWriter(rcp_writer , fieldnames=[\"device_id\" , \"morning_peak(8-11)\" , \"free_hour\" , \"evening_peak(3-7)\"])\n",
    "    writer.writeheader()\n",
    "    for i in range(0,41):\n",
    "        writer.writerow({\n",
    "            \"device_id\":buses[i] , \n",
    "            \"morning_peak(8-11)\":temp_recorder[i][0],\n",
    "            \"free_hour\":temp_recorder[i][1],\n",
    "            \"evening_peak(3-7)\":temp_recorder[i][2]\n",
    "            })      \n",
    "    rcp_writer.close()\n",
    "with open(dpd , \"w\") as dpd_writer:\n",
    "    writer = csv.DictWriter(dpd_writer , fieldnames = [\"date\" ,\"data_count\" , \"morning_rush\" , \"free\" , \"evening_rush\"])\n",
    "    writer.writeheader()\n",
    "    for key,value in dict_dates.items():\n",
    "        extra_val = dict_dates_2[key]\n",
    "        temp_dict = {\n",
    "            \"date\":key,\n",
    "            \"data_count\":value,\n",
    "            \"morning_rush\":extra_val[0],\n",
    "            \"free\":extra_val[1],\n",
    "            \"evening_rush\":extra_val[2]\n",
    "        } \n",
    "        writer.writerow(temp_dict)\n",
    "    dpd_writer.close()\n",
    "            \n",
    "    # for key,value in total_buses.iter():\n",
    "    #     print(f\"Bus {key} has {value} numbers of log in the dataset \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ee86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract categories and values\n",
    "df = pd.read_csv(rcp)\n",
    "categories = df['device_id']\n",
    "group_a_values = df['morning_peak(8-11)']\n",
    "group_b_values = df['free_hour']\n",
    "group_c_values = df['evening_peak(3-7)']\n",
    "\n",
    "# Set bar width and positions\n",
    "bar_width = 0.2\n",
    "index = np.arange(len(categories)) # Numerical positions for categories\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "\n",
    "# Plot each group of bars\n",
    "bar1 = ax.bar(index - bar_width, group_a_values, bar_width, label='morning_peak(8-11)')\n",
    "bar2 = ax.bar(index, group_b_values, bar_width, label='free_hour')\n",
    "bar3 = ax.bar(index + bar_width, group_c_values, bar_width, label='evening_peak(3-7)')\n",
    "\n",
    "\n",
    "ax.set_xlabel('Device_id')\n",
    "ax.set_ylabel('No of datas')\n",
    "ax.set_title('Mahanagar dataset 1.0')\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167a6eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract categories and values\n",
    "df = pd.read_csv(dpd)\n",
    "categories = df['date']\n",
    "\n",
    "group_a_values = df['morning_rush']\n",
    "group_b_values = df['free']\n",
    "group_c_values = df['evening_rush']\n",
    "group_d_values = df[\"data_count\"]\n",
    "# Set bar width and positions\n",
    "bar_width = 0.2\n",
    "index = np.arange(len(categories)) # Numerical positions for categories\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(26, 6))\n",
    "\n",
    "# Plot each group of bars\n",
    "bar1 = ax.bar(index - bar_width, group_a_values, bar_width, label='morning_peak')\n",
    "bar2 = ax.bar(index, group_b_values, bar_width, label='free_hour')\n",
    "bar3 = ax.bar(index + bar_width, group_c_values, bar_width, label='evening_peak')\n",
    "bar4 = ax.bar(index + bar_width*1.5, group_d_values, bar_width, label=\"total count\") \n",
    "\n",
    "ax.set_xlabel('dates')\n",
    "ax.set_ylabel(\"data_counts\")\n",
    "ax.set_title('Mahanagar dataset 1.1')\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5900789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_info = {\n",
    "    key:[] for key in buses\n",
    "}\n",
    "import math\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Returns the Haversine distance between two lat/lon points in meters.\n",
    "    \"\"\"\n",
    "    R = 6371000  # Earth radius in meters\n",
    "\n",
    "    phi1 = math.radians(lat1)\n",
    "    phi2 = math.radians(lat2)\n",
    "    dphi = math.radians(lat2 - lat1)\n",
    "    dlambda = math.radians(lon2 - lon1)\n",
    "\n",
    "    a = math.sin(dphi / 2)**2 + math.cos(phi1) * math.cos(phi2) * math.sin(dlambda / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    return R * c\n",
    "    \n",
    "with open(save_path , \"r\") as file:\n",
    "    \n",
    "    take_date = dates_given[-1]\n",
    "    exp_yr , exp_mon,exp_day = make_int(take_date)\n",
    "    print(exp_yr)\n",
    "    reader = csv.DictReader(file)\n",
    "    for line in reader:\n",
    "        \n",
    "        date_choose = line[\"fixTime\"]\n",
    "        date_time = date_choose.split()\n",
    "        \n",
    "        yr , mon,day = make_int(date_time[0])\n",
    "        curr_hr ,curr_min , curr_sec = 0,0,0\n",
    "        if yr == exp_yr and exp_mon == mon and exp_day == day:\n",
    "            hr,min,sec = make_int(date_time[1])\n",
    "            if hr==curr_hr and min==curr_min and curr_sec == sec:\n",
    "                \n",
    "                continue\n",
    "                \n",
    "            #[(hr,min,sec),lat,lon]\n",
    "            try:\n",
    "                x = dict_info[int(line[\"deviceId\"])][-1] \n",
    "                lat , lon = float(line[\"latitude\"]) , float(line[\"longitude\"])\n",
    "            except:\n",
    "                lat , lon = float(line[\"latitude\"]) , float(line[\"longitude\"])\n",
    "            \n",
    "                dict_info[int(line[\"deviceId\"])].append([(hr,min,sec) , lat,lon])\n",
    "                \n",
    "                continue\n",
    "            \n",
    "            \n",
    "            #calc. diffn in time \n",
    "            # time_taken = (abs(hr-prev_hr))*3600 + (abs(prev_min-min))*60 + (abs(sec-prev_sec))\n",
    "            # dist = haversine_distance(lat,lon , prev_lat,prev_lon)\n",
    "            dict_info[int(line[\"deviceId\"])].append([(hr,min,sec) , lat,lon])\n",
    "            curr_hr , curr_min,curr_sec = hr,min,sec\n",
    "    file.close()     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd3155",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = {\n",
    "    key:[[]] for key in buses\n",
    "}\n",
    "sorting_list = []\n",
    "fixed_point = [27.678786911652914, 85.3494674406196] #koteshwor\n",
    "def time_to_seconds(h, m, s):\n",
    "    return h*3600 + m*60 + s\n",
    "\n",
    "\n",
    "for key,value in dict_info.items():\n",
    "    print(key)\n",
    "    if value ==[]:\n",
    "        continue\n",
    "    sorted_values = sorted(value , key=lambda x:x[0] , reverse = False)\n",
    "    prev_hr,prev_min ,prev_sec = 0,0,0\n",
    "    prev_lat , prev_lon = 0,0\n",
    "    total_distance_covered=0\n",
    "    for x in sorted_values:\n",
    "        hr ,min,sec=x[0]\n",
    "        #print(prev_hr,prev_min , prev_sec , prev_lat,prev_lon)\n",
    "        lat,lon = x[1],x[2]\n",
    "        #print(key , hr,min,sec,lat,lon)\n",
    "        \n",
    "        if ((prev_hr ==0) and (prev_min==0) and (prev_sec==0)):\n",
    "            prev_hr , prev_min,prev_sec = x[0]\n",
    "            prev_lat , prev_lon = x[1],x[2]\n",
    "            continue \n",
    "            #calc. diffn in time\n",
    "        \n",
    "        t1 = time_to_seconds(prev_hr, prev_min, prev_sec)\n",
    "        t2 = time_to_seconds(hr, min, sec)\n",
    "\n",
    "        time_taken = t2 - t1\n",
    "        \n",
    "        dist = haversine_distance(lat,lon , prev_lat,prev_lon)\n",
    "        total_distance_covered +=dist\n",
    "\n",
    "        fixed_dist = haversine_distance(lat,lon , fixed_point[0],fixed_point[1])\n",
    "        sorting_list.append([(hr,min,sec) , lat,lon,time_taken , dist,total_distance_covered,fixed_dist])\n",
    "        prev_hr , prev_min,prev_sec = x[0]\n",
    "        prev_lat , prev_lon = x[1],x[2]\n",
    "    #sorting_list = sorted(sorting_list,key = lambda x:x[0] , reverse = False)\n",
    "    sorted_dict[key] = sorting_list \n",
    "    print(sorted_dict[key])\n",
    "with open(save_path_2,\"w\") as file: \n",
    "    writer = csv.DictWriter(file , fieldnames=[\"deviceId\",\"time\",\"lat\",\"lon\",\"time_taken\",\"distance\",\"total_distance\",\"from_koteshwor\"])\n",
    "    writer.writeheader()\n",
    "    for key,value in sorted_dict.items():\n",
    "        for val in value:\n",
    "            if val ==[] or val[3]==0:\n",
    "                continue\n",
    "            \n",
    "            dict_to_write = {\n",
    "            \"deviceId\":key,\n",
    "            \"time\":val[0],\n",
    "            \"lat\":val[1],\n",
    "            \"lon\":val[2],\n",
    "            \"time_taken\":val[3],\n",
    "            \"distance\":val[4],\n",
    "            \"total_distance\":val[5],\n",
    "            \"from_koteshwor\":val[6]\n",
    "            }\n",
    "            writer.writerow(dict_to_write)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1460313",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path_2 , \"r\") as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    #0 for time and 1 for distance covered\n",
    "    dict_ploting = {\n",
    "        key:[\n",
    "            [],[]\n",
    "            ] for key in buses\n",
    "    }\n",
    "    curr_dv_id =0 \n",
    "    for line in reader:\n",
    "        dict_ploting[int(line[\"deviceId\"])][0].append(line[\"time\"])\n",
    "        dict_ploting[int(line[\"deviceId\"])][1].append(float(line[\"total_distance\"]))\n",
    "for bus_id, (time_list, distance_list) in dict_ploting.items():\n",
    "    plt.figure(figsize=(80, 40))\n",
    "    plt.plot(time_list, distance_list, marker='o')\n",
    "    plt.title(f'Distance vs Time for {bus_id}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Distance Covered')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a0bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import ast   # <-- To safely convert \"(15, 18, 29)\" into a real tuple\n",
    "\n",
    "dict_ploting = {key: [[], []] for key in buses}\n",
    "\n",
    "with open(save_path_2, \"r\") as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for line in reader:\n",
    "        dev_id = int(line[\"deviceId\"])\n",
    "\n",
    "        # Convert string \"(15, 18, 29)\" into real tuple\n",
    "        t = ast.literal_eval(line[\"time\"])\n",
    "        dict_ploting[dev_id][0].append(t)\n",
    "\n",
    "        # Total distance\n",
    "        dist = float(line[\"total_distance\"])\n",
    "        dict_ploting[dev_id][1].append(dist)\n",
    "\n",
    "# ---- PLOT ----\n",
    "for bus_id, (time_list, distance_list) in dict_ploting.items():\n",
    "\n",
    "    x = list(range(len(time_list)))   # equal interval x-axis\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.plot(x, distance_list, marker='o')\n",
    "\n",
    "    plt.title(f\"Distance vs Time for Bus {bus_id}\")\n",
    "    plt.xlabel(\"Equal Interval Points\")\n",
    "    plt.ylabel(\"Distance Covered\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Convert tuple to a readable label\n",
    "    time_labels = [f\"{h:02d}:{m:02d}:{s:02d}\" for h, m, s in time_list]\n",
    "\n",
    "    # Show max 20 x-tick labels to avoid clutter\n",
    "    step = max(1, len(time_labels) // 20)\n",
    "    plt.xticks(x[::step], time_labels[::step], rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(folder_img, dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e75d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stations = { \n",
    "    \"clockwise\":{ \n",
    "        \"koteshwor\":[27.67329550, 85.34312386, 27.68230450, 85.35327614],\n",
    "        \"tinkune\":[27.68159550, 85.34882386, 27.69060450, 85.35897614],\n",
    "        \"gausala\":[27.70109550, 85.35232386, 27.71010450, 85.36247614],\n",
    "        \"chabahil\":[27.72439550, 85.35102386, 27.73340450, 85.36117614],\n",
    "        \"narayan_gopal_chowk\":[27.74699550, 85.33992386, 27.75600450, 85.35007614],\n",
    "        \"maharajgunj\":[27.73319550, 85.32832386, 27.74220450, 85.33847614],\n",
    "        \"gangabu\":[27.72959550, 85.31282386, 27.73860450, 85.32297614], # New Bus Park Area\n",
    "        \"balaju_bypass\":[27.73029550, 85.29162386, 27.73930450, 85.30177614],\n",
    "        \"swoyambhu\":[27.71179550, 85.27972386, 27.72080450, 85.28987614],\n",
    "        \"kalanki\":[27.68549550, 85.26982386, 27.69450450, 85.27997614],\n",
    "        \"rabi_bhawan\":[27.67999550, 85.28892386, 27.68900450, 85.29907614],\n",
    "        \"balkhu\":[27.66949550, 85.29692386, 27.67850450, 85.30707614],\n",
    "        \"bagdol\":[27.66349550, 85.31092386, 27.67250450, 85.32107614],\n",
    "        \"satdobato\":[27.65349550, 85.31642386, 27.66250450, 85.32657614],\n",
    "        \"gwarko\":[27.66529550, 85.32882386, 27.67430450, 85.33897614]\n",
    "    }, \n",
    "    \"anti-clockwise\":{ \n",
    "        \"koteshwor\":[27.67329550, 85.34312386, 27.68230450, 85.35327614],\n",
    "        \"tinkune\":[27.68159550, 85.34882386, 27.69060450, 85.35897614],\n",
    "        \"gausala\":[27.70109550, 85.35232386, 27.71010450, 85.36247614],\n",
    "        \"chabahil\":[27.72439550, 85.35102386, 27.73340450, 85.36117614],\n",
    "        \"narayan_gopal_chowk\":[27.74699550, 85.33992386, 27.75600450, 85.35007614],\n",
    "        \"maharajgunj\":[27.73319550, 85.32832386, 27.74220450, 85.33847614],\n",
    "        \"gangabu\":[27.72959550, 85.31282386, 27.73860450, 85.32297614],\n",
    "        \"balaju_bypass\":[27.73029550, 85.29162386, 27.73930450, 85.30177614],\n",
    "        \"swoyambhu\":[27.71179550, 85.27972386, 27.72080450, 85.28987614],\n",
    "        \"kalanki\":[27.68549550, 85.26982386, 27.69450450, 85.27997614],\n",
    "        \"rabi_bhawan\":[27.67999550, 85.28892386, 27.68900450, 85.29907614],\n",
    "        \"balkhu\":[27.66949550, 85.29692386, 27.67850450, 85.30707614],\n",
    "        \"bagdol\":[27.66349550, 85.31092386, 27.67250450, 85.32107614],\n",
    "        \"satdobato\":[27.65349550, 85.31642386, 27.66250450, 85.32657614],\n",
    "        \"gwarko\":[27.66529550, 85.32882386, 27.67430450, 85.33897614]\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d805db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import ast \n",
    "import sys \n",
    "\n",
    "# ===================================================================\n",
    "# 0. SETUP: Helper Functions and Constants\n",
    "# ===================================================================\n",
    "\n",
    "# --- Constants & Paths ---\n",
    "buses = [130, 2, 131, 132, 133, 134, 135, 136, 200, 137, 73, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 169]\n",
    "save_path_2 = \"data_tracking.csv\"      # Original file (used as input source)\n",
    "output_path_2 = \"new_processed_data.csv\" # NEW file for trajectory output (to avoid overwriting)\n",
    "folder_img = \"img_output\" \n",
    "os.makedirs(folder_img, exist_ok=True)\n",
    "fixed_point = [27.678786911652914, 85.3494674406196] # Koteshwor coordinates\n",
    "\n",
    "# Bus Station Bounding Boxes\n",
    "STATIONS = {\n",
    "    \"koteshwor\":[27.67329550, 85.34312386, 27.68230450, 85.35327614],\n",
    "    \"tinkune\":[27.68159550, 85.34882386, 27.69060450, 85.35897614],\n",
    "    \"gausala\":[27.70109550, 85.35232386, 27.71010450, 85.36247614],\n",
    "    \"chabahil\":[27.72439550, 85.35102386, 27.73340450, 85.36117614],\n",
    "    \"narayan_gopal_chowk\":[27.74699550, 85.33992386, 27.75600450, 85.35007614],\n",
    "    \"maharajgunj\":[27.73319550, 85.32832386, 27.74220450, 85.33847614],\n",
    "    \"gangabu\":[27.72959550, 85.31282386, 27.73860450, 85.32297614],\n",
    "    \"balaju_bypass\":[27.73029550, 85.29162386, 27.73930450, 85.30177614],\n",
    "    \"swoyambhu\":[27.71179550, 85.27972386, 27.72080450, 85.28987614],\n",
    "    \"kalanki\":[27.68549550, 85.26982386, 27.69450450, 85.27997614],\n",
    "    \"rabi_bhawan\":[27.67999550, 85.28892386, 27.68900450, 85.29907614],\n",
    "    \"balkhu\":[27.66949550, 85.29692386, 27.67850450, 85.30707614],\n",
    "    \"bagdol\":[27.66349550, 85.31092386, 27.67250450, 85.32107614],\n",
    "    \"satdobato\":[27.65349550, 85.31642386, 27.66250450, 85.32657614],\n",
    "    \"gwarko\":[27.66529550, 85.32882386, 27.67430450, 85.33897614]\n",
    "}\n",
    "STATION_NAMES = list(STATIONS.keys())\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def time_to_seconds(h, m, s):\n",
    "    return h * 3600 + m * 60 + s\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  # Earth radius in meters\n",
    "    phi1 = math.radians(lat1)\n",
    "    phi2 = math.radians(lat2)\n",
    "    dphi = math.radians(lat2 - lat1)\n",
    "    dlambda = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dphi / 2)**2 + math.cos(phi1) * math.cos(phi2) * math.sin(dlambda / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "def get_current_station(lat, lon):\n",
    "    for name, bbox in STATIONS.items():\n",
    "        min_lat, min_lon, max_lat, max_lon = bbox\n",
    "        if min_lat <= lat <= max_lat and min_lon <= lon <= max_lon:\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "# ===================================================================\n",
    "# 1. DATA LOADING LOGIC (Loads from data_tracking.csv)\n",
    "# ===================================================================\n",
    "\n",
    "dict_info = {key: [] for key in buses}\n",
    "data_loaded_from_csv = False\n",
    "\n",
    "if os.path.exists(save_path_2):\n",
    "    print(f\"Attempting to load raw data from original file: {save_path_2}...\")\n",
    "    try:\n",
    "        df_load = pd.read_csv(save_path_2)\n",
    "        df_load = df_load[df_load['time'].astype(str).str.startswith('(')]\n",
    "        \n",
    "        for index, row in df_load.iterrows():\n",
    "            deviceId = row['deviceId']\n",
    "            time_tuple = ast.literal_eval(row['time'])\n",
    "            \n",
    "            # Reconstruct the raw data format: [[h, m, s], lat, lon]\n",
    "            dict_info.setdefault(deviceId, []).append([\n",
    "                [time_tuple[0], time_tuple[1], time_tuple[2]], \n",
    "                row['lat'], \n",
    "                row['lon']\n",
    "            ])\n",
    "        \n",
    "        if any(dict_info.values()):\n",
    "            data_loaded_from_csv = True\n",
    "            print(f\"Successfully loaded raw data for {len([k for k, v in dict_info.items() if v])} buses.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {save_path_2}: {e}. Falling back to placeholder data.\", file=sys.stderr)\n",
    "        \n",
    "# FALLBACK: Placeholder data for bus 130 if no real data was loaded\n",
    "if not data_loaded_from_csv:\n",
    "    print(\"WARNING: Input data file was not found/empty. Using placeholder data for bus 130.\")\n",
    "    dict_info[130] = [\n",
    "        [[7, 0, 0], 27.6780, 85.3480],      \n",
    "        [[7, 2, 0], 27.6850, 85.3000],      \n",
    "        [[7, 10, 0], 27.6900, 85.2750],     \n",
    "        [[7, 13, 0], 27.6900, 85.2750],     \n",
    "        [[7, 14, 0], 27.6950, 85.2700],     \n",
    "        [[7, 30, 0], 27.7300, 85.3180],     \n",
    "        [[7, 35, 0], 27.7300, 85.3180],     \n",
    "        [[8, 0, 0], 27.6780, 85.3480]       \n",
    "    ]\n",
    "\n",
    "buses_with_data = [k for k, v in dict_info.items() if v]\n",
    "\n",
    "# ===================================================================\n",
    "# 2. DATA PROCESSING & SAVING TO NEW CSV\n",
    "# ===================================================================\n",
    "\n",
    "sorted_dict = {key: [] for key in buses}\n",
    "\n",
    "for key, value in dict_info.items():\n",
    "    if key not in buses_with_data: continue\n",
    "    \n",
    "    print(f\"\\nCalculating trajectory metrics for bus {key}...\")\n",
    "    \n",
    "    sorted_values = sorted(value, key=lambda x: time_to_seconds(*x[0]), reverse=False)\n",
    "    \n",
    "    prev_hr, prev_min, prev_sec = 0, 0, 0\n",
    "    prev_lat, prev_lon = 0, 0\n",
    "    total_distance_covered = 0\n",
    "    \n",
    "    sorting_list = []\n",
    "    \n",
    "    for x in sorted_values:\n",
    "        hr, min, sec = x[0]\n",
    "        lat, lon = x[1], x[2]\n",
    "        \n",
    "        if ((prev_hr == 0) and (prev_min == 0) and (prev_sec == 0)):\n",
    "            prev_hr, prev_min, prev_sec = x[0]\n",
    "            prev_lat, prev_lon = x[1], x[2]\n",
    "            continue\n",
    "            \n",
    "        t1 = time_to_seconds(prev_hr, prev_min, prev_sec)\n",
    "        t2 = time_to_seconds(hr, min, sec)\n",
    "\n",
    "        time_taken = t2 - t1\n",
    "        \n",
    "        dist = haversine_distance(lat, lon, prev_lat, prev_lon)\n",
    "        total_distance_covered += dist\n",
    "\n",
    "        fixed_dist = haversine_distance(lat, lon, fixed_point[0], fixed_point[1])\n",
    "        sorting_list.append([(hr, min, sec), lat, lon, time_taken, dist, total_distance_covered, fixed_dist])\n",
    "        \n",
    "        prev_hr, prev_min, prev_sec = x[0]\n",
    "        prev_lat, prev_lon = x[1], x[2]\n",
    "        \n",
    "    sorted_dict[key] = sorting_list\n",
    "    \n",
    "# Write the processed data to the NEW file (output_path_2)\n",
    "print(f\"\\nSaving detailed trajectory to NEW file: {output_path_2}...\")\n",
    "with open(output_path_2, \"w\", newline=\"\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"deviceId\", \"time\", \"lat\", \"lon\", \"time_taken\", \"distance\", \"total_distance\", \"from_koteshwor\"])\n",
    "    writer.writeheader()\n",
    "    for key, value in sorted_dict.items():\n",
    "        for val in value:\n",
    "            if val == [] or val[3] == 0:\n",
    "                continue\n",
    "            \n",
    "            dict_to_write = {\n",
    "                \"deviceId\": key,\n",
    "                \"time\": str(val[0]), \n",
    "                \"lat\": val[1],\n",
    "                \"lon\": val[2],\n",
    "                \"time_taken\": val[3],\n",
    "                \"distance\": val[4],\n",
    "                \"total_distance\": val[5],\n",
    "                \"from_koteshwor\": val[6]\n",
    "            }\n",
    "            writer.writerow(dict_to_write)\n",
    "    print(f\"{output_path_2} saved. Original file {save_path_2} was not modified.\")\n",
    "    file.close()\n",
    "\n",
    "# ===================================================================\n",
    "# 3. ADVANCED ANALYSIS: Rounds, Waiting, and Travel Time\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\nStarting Advanced Analysis (Rounds, Waiting, Travel Time)...\")\n",
    "\n",
    "# Load data from the NEWLY processed file\n",
    "df_full = pd.read_csv(output_path_2)\n",
    "df_full['time'] = df_full['time'].apply(ast.literal_eval)\n",
    "df_full['total_seconds'] = df_full['time'].apply(lambda t: time_to_seconds(t[0], t[1], t[2]))\n",
    "df_full['station'] = df_full.apply(lambda row: get_current_station(row['lat'], row['lon']), axis=1)\n",
    "\n",
    "round_trip_data = defaultdict(list)\n",
    "all_wait_times = defaultdict(list)\n",
    "all_travel_times = defaultdict(list) \n",
    "\n",
    "total_passes = 0\n",
    "\n",
    "for deviceId in buses_with_data:\n",
    "    df = df_full[df_full['deviceId'] == deviceId].sort_values('total_seconds').reset_index(drop=True)\n",
    "    \n",
    "    current_station = None\n",
    "    station_entry_time = None\n",
    "    koteshwor_exit_time = None\n",
    "    current_lap = 1\n",
    "    last_station_name = None\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        next_station = row['station']\n",
    "        \n",
    "        # --- Station Entry/Exit and Waiting Time/Travel Time ---\n",
    "        if next_station and next_station != current_station:\n",
    "            station_entry_time = row['total_seconds']\n",
    "            \n",
    "            if last_station_name == 'koteshwor' and next_station != 'koteshwor' and koteshwor_exit_time is not None:\n",
    "                travel_time = station_entry_time - koteshwor_exit_time\n",
    "                all_travel_times[next_station].append(travel_time)\n",
    "\n",
    "        elif not next_station and current_station:\n",
    "            if station_entry_time is not None:\n",
    "                wait_time = row['total_seconds'] - station_entry_time\n",
    "                all_wait_times[current_station].append(wait_time)\n",
    "                station_entry_time = None\n",
    "            \n",
    "            last_station_name = current_station\n",
    "\n",
    "        # --- Round Trip Detection ---\n",
    "        if current_station == 'koteshwor' and next_station != 'koteshwor':\n",
    "            koteshwor_exit_time = row['total_seconds']\n",
    "            \n",
    "        elif current_station != 'koteshwor' and next_station == 'koteshwor':\n",
    "            if koteshwor_exit_time is not None:\n",
    "                lap_duration = row['total_seconds'] - koteshwor_exit_time\n",
    "                round_trip_data[deviceId].append({\n",
    "                    'lap_number': current_lap,\n",
    "                    'start_time_seconds': koteshwor_exit_time,\n",
    "                    'end_time_seconds': row['total_seconds'],\n",
    "                    'time_taken_seconds': lap_duration\n",
    "                })\n",
    "                current_lap += 1\n",
    "                total_passes += 1\n",
    "                koteshwor_exit_time = None \n",
    "                \n",
    "        current_station = next_station\n",
    "        \n",
    "print(f\"Total calculated passes across all buses: {total_passes}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 4. GENERATE CSV FOR ROUND TRIPS (Per-Bus CSV)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\nGenerating round trip CSV files...\")\n",
    "for deviceId, laps in round_trip_data.items():\n",
    "    save_path_bus = f\"{deviceId}_round_trips.csv\"\n",
    "    with open(save_path_bus, \"w\", newline=\"\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"busId\", \"lap_number\", \"start_time_seconds\", \"end_time_seconds\", \"time_taken_seconds\"])\n",
    "        writer.writeheader()\n",
    "        for lap in laps:\n",
    "            writer.writerow(lap)\n",
    "    print(f\"Generated {save_path_bus}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 5. HEATMAP DATA CALCULATION \n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\nCalculating Heatmap metrics...\")\n",
    "\n",
    "heatmap_data = pd.DataFrame(index=STATION_NAMES, columns=STATION_NAMES, dtype=float)\n",
    "\n",
    "# 1. Diagonal: Average Waiting Time (Station X vs. Station X)\n",
    "for station in STATION_NAMES:\n",
    "    if all_wait_times[station]:\n",
    "        avg_wait_time = np.mean(all_wait_times[station])\n",
    "        heatmap_data.loc[station, station] = avg_wait_time\n",
    "    else:\n",
    "        heatmap_data.loc[station, station] = 0.0\n",
    "\n",
    "# 2. Off-Diagonal: Average Travel Time (Koteshwor vs. Station X)\n",
    "for station in STATION_NAMES:\n",
    "    if station == 'koteshwor':\n",
    "        continue\n",
    "        \n",
    "    if all_travel_times[station]:\n",
    "        avg_travel_time = np.mean(all_travel_times[station])\n",
    "        heatmap_data.loc['koteshwor', station] = avg_travel_time\n",
    "        \n",
    "heatmap_data = heatmap_data.fillna(0.0)\n",
    "print(\"\\n--- Heatmap Data (Time in Seconds) ---\")\n",
    "print(heatmap_data)\n",
    "\n",
    "# ===================================================================\n",
    "# 6. GENERATE AND SAVE HEATMAP\n",
    "# ===================================================================\n",
    "\n",
    "print(f\"\\nGenerating and saving heatmap to {folder_img}/bus_time_heatmap.png...\")\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(\n",
    "    heatmap_data, \n",
    "    annot=True, \n",
    "    fmt=\".1f\", \n",
    "    cmap=\"YlGnBu\", \n",
    "    linewidths=.5,\n",
    "    cbar_kws={'label': 'Time (Seconds)'}\n",
    ")\n",
    "plt.title('Bus Time Metrics: Waiting Time (Diagonal) & Koteshwor Travel Time (Row)')\n",
    "plt.xlabel('Destination Station')\n",
    "plt.ylabel('Source Station')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{folder_img}/bus_time_heatmap.png')\n",
    "print(\"Heatmap saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mahanagar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
